# Model Configuration
MODEL_PATH=/path/to/model
MODEL_TYPE=example_vlm
DEVICE=auto

# Processing Configuration
DEFAULT_FPS=2.0
MAX_BATCH_SIZE=8
INFERENCE_TIMEOUT=30.0
FRAME_TIMEOUT=5.0

# Redis Configuration
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_STREAM_KEY=video_frames
REDIS_PASSWORD=
REDIS_SOCKET_TIMEOUT=5.0

# API Configuration
API_KEY=
API_TITLE=Free-Roam Inference Service
API_VERSION=1.0.0
CORS_ORIGINS=*
RATE_LIMIT_PER_MINUTE=60

# Logging Configuration
LOG_LEVEL=INFO
LOG_FORMAT=json

# Server Configuration
HOST=0.0.0.0
PORT=8000
WORKERS=1

# Memory Management
MAX_CONCURRENT_STREAMS=10
MEMORY_CLEANUP_INTERVAL=100
